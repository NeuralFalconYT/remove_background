{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9nh7anE6lMI_"
      },
      "outputs": [],
      "source": [
        "#@title Install and restart\n",
        "# !pip install torch  #version 2.5.1+cu121\n",
        "# !pip install torchvision #version 0.20.1+cu121\n",
        "# !pip install pillow>=11.0.0\n",
        "# !pip install transformers>=4.46.2\n",
        "!pip install kornia>=0.7.4\n",
        "!pip install gradio>=5.6.0\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import time\n",
        "time.sleep(5)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path=\"/content\""
      ],
      "metadata": {
        "id": "G7va62Ag_2yA"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downalod & load RMBG-2.0 Model\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from transformers import AutoModelForImageSegmentation\n",
        "\n",
        "model = AutoModelForImageSegmentation.from_pretrained('briaai/RMBG-2.0', trust_remote_code=True)\n",
        "torch.set_float32_matmul_precision(['high', 'highest'][0])\n",
        "model.to('cuda')\n",
        "model.eval()\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qjvvs3Ewln54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utils\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "import re\n",
        "import uuid\n",
        "\n",
        "def create_directory(directory_path):\n",
        "    if os.path.exists(directory_path):\n",
        "        shutil.rmtree(directory_path)\n",
        "    os.makedirs(directory_path)\n",
        "\n",
        "def extract_frames(video_path):\n",
        "  directory_path = f\"{base_path}/images\"\n",
        "  create_directory(directory_path)\n",
        "  command=f\"ffmpeg -i {video_path} {base_path}/images/%07d.png\"\n",
        "  var=os.system(command)\n",
        "\n",
        "  if var==0:\n",
        "    print(\"We extracted frames Successfully\")\n",
        "    print(f\"Number of Images {len(os.listdir(directory_path))}\")\n",
        "    return True\n",
        "  else:\n",
        "    print(\"Failed to extract frames\")\n",
        "    print(command)\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def video_size(video_path):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Unable to open video: {video_path}\")\n",
        "\n",
        "    # Get width, height, and FPS\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Release the video capture object\n",
        "    cap.release()\n",
        "\n",
        "    return (width, height),fps\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def make_green_screen(input_image_path):\n",
        "    ## Generate the save path for the new image\n",
        "    # base_name = os.path.splitext(os.path.basename(input_image_path))[0]\n",
        "    # new_file_name = f\"{base_name}_remove_background.png\"\n",
        "    # save_image_path = os.path.join(os.path.dirname(input_image_path), new_file_name)\n",
        "\n",
        "    # Open the input image\n",
        "    image = Image.open(input_image_path).convert(\"RGB\")  # Ensure image is in RGB mode\n",
        "    image_size= image.size\n",
        "    image_size= (1024,1024)\n",
        "    transform_image = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    # Transform the image\n",
        "    input_images = transform_image(image).unsqueeze(0).to('cuda')  # Prepare image for model\n",
        "\n",
        "    # Predict mask using the model\n",
        "    with torch.no_grad():\n",
        "        preds = model(input_images)[-1].sigmoid().cpu()\n",
        "    pred = preds[0].squeeze()\n",
        "\n",
        "    # Convert the prediction to a PIL mask\n",
        "    pred_pil = transforms.ToPILImage()(pred)\n",
        "    mask = pred_pil.resize(image.size)\n",
        "\n",
        "    # Create a green background image\n",
        "    green_background = Image.new(\"RGBA\", image.size, (0, 255, 0, 255))  # Green background with full opacity\n",
        "\n",
        "    # Add the alpha channel (mask) to the original image\n",
        "    image.putalpha(mask)\n",
        "\n",
        "    # Composite the green background with the original image using the alpha mask\n",
        "    final_image = Image.alpha_composite(green_background, image)\n",
        "    final_image_np = np.array(final_image)\n",
        "    # If the image has an alpha channel (RGBA), convert it to RGB\n",
        "    if final_image_np.shape[-1] == 4:  # Check if the image has 4 channels\n",
        "      final_image_np = final_image_np[:, :, :3]  # Drop the alpha channel\n",
        "    # Convert RGB to BGR (OpenCV uses BGR format)\n",
        "    final_image_cv = final_image_np[:, :, ::-1]\n",
        "    # cv2.imwrite(\"final_image_cv.png\", final_image_cv)\n",
        "    # Save the resulting image\n",
        "    # final_image.save(save_image_path)\n",
        "    # return save_image_path\n",
        "    return final_image_cv\n",
        "\n",
        "def process_video(video_path):\n",
        "  sucess=extract_frames(video_path)\n",
        "  if sucess==False:\n",
        "    return\n",
        "  temp_video_folder = f'{base_path}/video_chunks'\n",
        "  create_directory(temp_video_folder)\n",
        "  frames_folder=f\"{base_path}/images\"\n",
        "  dir_list = [file for file in os.listdir(frames_folder) if file.endswith(('.jpg', '.png'))]\n",
        "  dir_list.sort()\n",
        "  size,fps=video_size(video_path)\n",
        "  batch = 0\n",
        "  batchSize = 100\n",
        "  for i in tqdm(range(0, len(dir_list), batchSize), desc=\"Processing Batches\", unit=\"batch\"):\n",
        "  # for i in range(0, len(dir_list), batchSize):\n",
        "    img_array = []\n",
        "    start, end = i, i + batchSize\n",
        "    # print(\"processing \", start, end)\n",
        "    for filename in dir_list[start:end]:\n",
        "      filename = frames_folder +\"/\"+ filename\n",
        "      img = make_green_screen(filename)\n",
        "      img_array.append(img)\n",
        "    # Save the video as MP4\n",
        "    temp_video_path=temp_video_folder + f'/{str(batch).zfill(4)}.mp4'\n",
        "    out = cv2.VideoWriter(temp_video_path,\n",
        "    cv2.VideoWriter_fourcc(*'mp4v'), fps, size)\n",
        "    batch = batch + 1\n",
        "    for i in range(len(img_array)):\n",
        "      out.write(img_array[i])\n",
        "    out.release()\n",
        "    if os.path.exists(f\"{base_path}/gdrive/MyDrive/\"):\n",
        "      drive_folder=f\"{base_path}/gdrive/MyDrive/colab/video_chunks\"\n",
        "      os.makedirs(drive_folder, exist_ok=True)\n",
        "      temp_drive_video_path=f\"{drive_folder}\" + f'/{str(batch).zfill(4)}.mp4'\n",
        "      shutil.copy(temp_video_path,temp_drive_video_path)\n",
        "\n",
        "\n",
        "\n",
        "def make_video(video_path):\n",
        "  file_name=os.path.basename(video_path).split(\".mp4\")[0]\n",
        "  video_folder = f'{base_path}/video_chunks'\n",
        "  output_txt_file = f'{base_path}/join.txt'\n",
        "  video_files = [file for file in os.listdir(video_folder) if file.endswith('.mp4')]\n",
        "  video_files.sort()\n",
        "  with open(output_txt_file, 'w') as file:\n",
        "    for video_file in video_files:\n",
        "      file.write(f\"file '{os.path.join(video_folder, video_file)}'\\n\")\n",
        "  output_folder=f\"{base_path}/result\"\n",
        "  os.makedirs(output_folder, exist_ok=True)\n",
        "  join_command=f\"ffmpeg -f concat -safe 0 -i {base_path}/join.txt -c copy {output_folder}/{file_name}_join.mp4 -y\"\n",
        "  var1=os.system(join_command)\n",
        "  if var1==0:\n",
        "    extract_audio_command=f\"ffmpeg -i {video_path} {output_folder}/{file_name}.wav -y\"\n",
        "    var2=os.system(extract_audio_command)\n",
        "    if var2==0:\n",
        "      add_audio_command=f\"ffmpeg -i {output_folder}/{file_name}_join.mp4 -i {output_folder}/{file_name}.wav -c:v copy -map 0:v -map 1:a -y {output_folder}/{file_name}_green_screen.mp4\"\n",
        "      var3=os.system(add_audio_command)\n",
        "      if var3==0:\n",
        "        final_result=f\"{output_folder}/{file_name}_green_screen.mp4\"\n",
        "        print(f\"Green Screen video save at {final_result}\")\n",
        "        return final_result\n",
        "      else:\n",
        "        print(\"Faile to add audio in video\")\n",
        "        print(add_audio_command)\n",
        "    else:\n",
        "      print(f\"Failed to extract audio\")\n",
        "      print(extract_audio_command)\n",
        "    return f\"{output_folder}/{file_name}_join.mp4\"\n",
        "  else:\n",
        "    print(\"Video Marge Failed\")\n",
        "    print(join_command)\n",
        "\n",
        "\n",
        "\n",
        "def clean_file_name(file_path):\n",
        "    # Get the base file name and extension\n",
        "    file_name = os.path.basename(file_path)\n",
        "    file_name, file_extension = os.path.splitext(file_name)\n",
        "\n",
        "    # Replace non-alphanumeric characters with an underscore\n",
        "    cleaned = re.sub(r'[^a-zA-Z\\d]+', '_', file_name)\n",
        "\n",
        "    # Remove any multiple underscores\n",
        "    clean_file_name = re.sub(r'_+', '_', cleaned).strip('_')\n",
        "\n",
        "    # Generate a random UUID for uniqueness\n",
        "    random_uuid = uuid.uuid4().hex[:6]\n",
        "\n",
        "    # Combine cleaned file name with the original extension\n",
        "    clean_file_name=clean_file_name + f\"_{random_uuid}\" + file_extension\n",
        "    clean_file_path = os.path.join(os.path.dirname(file_path),clean_file_name )\n",
        "\n",
        "    return clean_file_path,clean_file_name\n",
        "\n",
        "\n",
        "def remove_background(upload_image_path):\n",
        "  upload_folder=f\"{base_path}/upload\"\n",
        "  _,clean_name=clean_file_name(upload_image_path)\n",
        "  input_image_path=f\"{upload_folder}/{clean_name}\"\n",
        "  shutil.copy(upload_image_path,input_image_path)\n",
        "  base_name = os.path.splitext(os.path.basename(input_image_path))[0]  # Get the base name without extension\n",
        "  new_file_name = f\"{base_name}_RMBG.png\"  # Append new suffix and change extension\n",
        "  save_image_path = os.path.join(os.path.dirname(input_image_path), new_file_name)  # Combine with directory\n",
        "  image = Image.open(input_image_path)\n",
        "  # image_size = image.size\n",
        "  image_size = (1024,1024)\n",
        "  transform_image = transforms.Compose([\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ])\n",
        "  input_images = transform_image(image).unsqueeze(0).to('cuda')\n",
        "  with torch.no_grad():\n",
        "      preds = model(input_images)[-1].sigmoid().cpu()\n",
        "  pred = preds[0].squeeze()\n",
        "  pred_pil = transforms.ToPILImage()(pred)\n",
        "  mask = pred_pil.resize(image.size)\n",
        "  image.putalpha(mask)\n",
        "  image.save(save_image_path)\n",
        "  return save_image_path\n",
        "\n",
        "def green_screen_pipeline(upload_video_path):\n",
        "  upload_folder=f\"{base_path}/upload\"\n",
        "  # os.makedirs(upload_folder, exist_ok=True)\n",
        "  _,clean_name=clean_file_name(upload_video_path)\n",
        "  video_path=f\"{upload_folder}/{clean_name}\"\n",
        "  shutil.copy(upload_video_path,video_path)\n",
        "  process_video(video_path)\n",
        "  green_screen_video_path=make_video(video_path)\n",
        "  return green_screen_video_path\n",
        "\n",
        "upload_folder=f\"{base_path}/upload\"\n",
        "os.makedirs(upload_folder, exist_ok=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xA0mVSocpfYw"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Gradio Interface\n",
        "import gradio as gr\n",
        "image_demo_inputs=[gr.File(label=\"Upload Single Image\",file_types=['image'],type='filepath')]\n",
        "image_demo_outputs=[gr.File(label=\"Download Image\", show_label=True)]\n",
        "image_demo = gr.Interface(fn=remove_background, inputs=image_demo_inputs,outputs=image_demo_outputs , title=\"RMBG-2.0 For Image\")\n",
        "video_demo_inputs=[gr.File(label=\"Upload a Video\",file_types=['.mp4'],type='filepath')]\n",
        "video_demo_outputs=[gr.File(label=\"Download Video\", show_label=True)]\n",
        "video_demo = gr.Interface(fn=green_screen_pipeline, inputs=video_demo_inputs,outputs=video_demo_outputs , title=\"RMBG-2.0 For Video\")\n",
        "demo = gr.TabbedInterface([image_demo,video_demo], [\"RMBG-2.0 For Image\", \"RMBG-2.0 For Video\"],title=\"Remove Background on Image & Video Using RMBG-2.0\")\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue().launch(allowed_paths=[f\"{base_path}/result\",f\"{base_path}/upload\"],debug=False,share=True)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "UnMJiQds-a90"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}